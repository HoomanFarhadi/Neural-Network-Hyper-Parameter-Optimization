# Neural-Network-Hyper-Parameter-Optimization
In this second part of a bigger project, a general neural network with back propagation was implemented from scratch in python.  Two methods of training, one with just the learning rate alpha and one with a momentum parameter mu for momentum based training were defined for the neural network. Then, a tuning algorithm that relied on searching the hyper parameter space using binary search ideas was innovated, and the performance was compared with a traditional grid search algorithm.
